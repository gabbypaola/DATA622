---
title: "DATA622 | Machine Learning and Big Data"
author: "Gabriella Martinez"
date: "3/5/2023"
output:
      html_document:
        toc: yes
        toc_float: yes
        theme: yeti
        highlight: kate
        font-family: "Arial"
        code_folding: show
---

# Assignment 1
1. Visit the following website and explore the range of sizes of this dataset (from 100 to 5 million records):
https://excelbianalytics.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/ or
(new) https://www.kaggle.com/datasets
2. Select 2 files to download. Based on your computer's capabilities (memory, CPU), select 2 files you can handle (recommended one small, one large)
3. Download the files
4. Review the structure and content of the tables, and think about the data sets (structure, size, dependencies, labels, etc)
5. Consider the similarities and differences in the two data sets you have downloaded
6. Think about how to analyze and predict an outcome based on the datasets available
7. Based on the data you have, think which two machine learning algorithms presented so far could be used to analyze the data

# Packages
```{r}
library(readr)
library(tidyverse)
library(tidymodels)
library(psych)
library(caret)
library(rpart)
library(rpart.plot)
```


# Load Data
```{r}
df5k <- read.csv("https://raw.githubusercontent.com/gabbypaola/DATA622/main/HW%201/5000%20Sales%20Records.csv")
df500k <- read.csv("https://raw.githubusercontent.com/gabbypaola/DATA622/main/HW%201/500000%20Sales%20Records.csv")
```

```{r}
glimpse(df5k)
```

```{r}
unique(df5k$Region)
unique(df5k$Country)
```
```{r}
unique(df5k$Item.Type)
unique(df5k$Sales.Channel)
```



```{r}
glimpse(df500k)
```

```{r}
unique(df500k$Region)
unique(df500k$Country)
```

```{r}
unique(df5k$Item.Type)
unique(df5k$Sales.Channel)
```


## Missing Data
```{r}
colSums(is.na(df5k))
```

```{r}
colSums(is.na(df500k))
```

## Distributions
```{r}
df5k_n <- df5k %>% 
  keep(is.numeric) %>% 
  select(-Order.ID)

describe(df5k_n, fast=TRUE) %>% 
  select(c(-vars,-n))
```

```{r}
df5k_n %>% 
  gather(variable, value, 1:6) %>%
  ggplot(aes(value)) +
    facet_wrap(~variable, scales = "free") +
    geom_density(fill = "steelblue", alpha=0.9, color="steelblue") +
    geom_histogram(aes(y=..density..), alpha=0.2, fill = "lightblue", color="lightblue", position="identity") +
    theme_minimal()
```



```{r}
df500k_n <- df500k %>% 
  keep(is.numeric) %>% 
  select(-Order.ID)

describe(df500k_n, fast=TRUE) %>% 
  select(c(-vars,-n))
```

```{r}
df500k_n %>% 
  gather(variable, value, 1:6) %>%
  ggplot(aes(value)) +
    facet_wrap(~variable, scales = "free") +
    geom_density(fill = "steelblue", alpha=0.9, color="steelblue") +
    geom_histogram(aes(y=..density..), alpha=0.2, fill = "lightblue", color="lightblue", position="identity") +
    theme_minimal()
```
## Dependencies and Definitions
`Total.Cost` = `Units.Sold` * `Unit.Cost`  
`Total.Revenue` = `Units.Sold` * `Unit.Price`  
`Total.Profit` = `Total.Revenue` - `Total.Cost` (where `Total.Cost` and `Total.Revenue` depend on `Units.Sold`, `Unit.Cost`, and `Unit.Price`)

`Order.Priority`: C(Critical), H(High), M(Medium) or L(Low)


## Variable Type Conversions
```{r}
df5k[['Order.Date']] <- as.Date(df5k[['Order.Date']], "%m/%d/%Y")
df5k[['Ship.Date']] <- as.Date(df5k[['Ship.Date']], "%m/%d/%Y")

df500k[['Order.Date']] <- as.Date(df500k[['Order.Date']], "%m/%d/%Y")
df500k[['Ship.Date']] <- as.Date(df500k[['Ship.Date']], "%m/%d/%Y")

df5k[['Sales.Channel']] <- as.factor(df5k[['Sales.Channel']])
df500k[['Sales.Channel']] <- as.factor(df500k[['Sales.Channel']])

df5k[['Order.Priority']] <- as.factor(df5k[['Order.Priority']])
df500k[['Order.Priority']] <- as.factor(df500k[['Order.Priority']])
```


# Model
## Decision Tree Models
Decision Tree models will be used for both the data with 5 thousand records as well as that with 500 thousand to predict the `Sales.Channel`, if an order will be conducted online or offline at a brick and mortar store.

^[https://www.gormanalysis.com/blog/decision-trees-in-r-using-rpart/]  

### 5k 
```{r}
#set seed for reproducibility
set.seed(6221)

train5k <- createDataPartition(df5k$`Sales.Channel`, p = 0.8, list=FALSE,times = 1)
train5k_data <- df5k[train5k,]
test5k_data <- df5k[-train5k,]

mytree1 <- rpart(`Sales.Channel` ~ `Region` + `Item.Type` + `Order.Priority` + `Total.Profit`,
                data= train5k_data, 
                method='class')
mytree1

mytree1 %>% rpart.plot(extra = 2)
```

### 500k
```{r}
#set seed for reproducibility
set.seed(6222)

train500k <- createDataPartition(df500k$`Sales.Channel`, p = 0.8, list=FALSE,times = 1)
train500k_data <- df500k[train500k,]
test500k_data <- df5k[-train500k,]

mytree2 <- rpart(`Sales.Channel` ~ `Region` + `Item.Type` + `Order.Priority` + `Total.Profit`,
                data= train500k_data, 
                method='class')
mytree2

mytree2 %>% rpart.plot(extra = 2)
```




